---
output: github_document

bibliography: man/bibliography/references.bib
csl: man/bibliography/nature.csl
link-citations: true
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "75%"
)

library(knitcitations)
cleanbib()
cite_options(citation_format = 'pandoc', style = "html", hyperlink = "to.bib")

```

# tidyTPP

<!-- badges: start -->
[![Codecov test coverage](https://codecov.io/gh/jackrogan/tidyTPP/graph/badge.svg?token=OFYPL51CV2)](https://app.codecov.io/gh/jackrogan/tidyTPP)
[![R-CMD-check](https://github.com/jackrogan/tidyTPP/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/jackrogan/tidyTPP/actions/workflows/R-CMD-check.yaml)
<!-- badges: end -->

## Introduction

tidyTPP provides an analysis pipeline for *Thermal Protein Profiling (TPP)*
proteomics data, with functions for reading in data from protein quantification
software, normalising data, analysis, and hit-finding.

The goal of tidyTPP is to provide a range of functions, each of which requires 
data in a straightforward data frame or [tibble](https://tibble.tidyverse.org/) 
and returns long-format data in a [tibble](https://tibble.tidyverse.org/) that 
are readily understood and easily used for further analysis. The style of data
is inspired by the [tidyverse](https://www.tidyverse.org/), and tidyTPP makes 
use of several tidyverse packages - in particular 
[tibble](https://tibble.tidyverse.org/) and 
[ggplot2](https://ggplot2.tidyverse.org/). 

### Currently supports:

Importing:

* Importing from Thermo Proteome Discoverer

* Importing from Spectronaut

* Importing with custom settings

Normalisation and Analysis:

* Single- and multi-threaded fitting of temperature-dependent protein melting
  curves *(TPP-TR)*
* Significance scores by melting point difference ($\Delta T_m$)
  `r citep("10.1126/science.1255784")`

* Significance scores by *non-pararametric analysis of response curves (NPARC)*
  `r citep("10.1074/mcp.TIR119.001481")`

Hit-finding

* Identifying hits by $\Delta T_m$ p-value

* Identifying its by *NPARC* F-score and p-value

Plotting

* Plotting *TPP-TR* melting-curves with 
  [ggplot2](https://ggplot2.tidyverse.org/)

## Installation

You can install the development version of tidyTPP from 
[GitHub](https://github.com/) with:

``` r
# install.packages("pak")
pak::pak("jackrogan/tidyTPP")
```

## Example: Pre-built pipeline

A version of the entire pipeline, with defaults to match common uses, is 
available with *apply_TPP_pipeline*. This executes the following sequence:

```{r, eval=FALSE}
import_TPP() |>
  normalise_TPP() |>
  analyse_TPP() |>
  export_TPP() |>
  get_TPP_hits()
```

The function uses the following defaults in addition to the default behaviour of 
each included function:

* Import supported proteomics quantification data formats

* Calculate *NPARC* and $\Delta T_m$ significance scores

* Report all hits with:

  - Adjusted *NPARC*-derived p-value < 0.05
  
  - $\Delta T_m$ in the same direction
  
  - $\Delta T_m$ *vs.* control > $\Delta T_m$ between controls
  
  - Full results table and identified hits are exported as *.xlsx* files with
    input file names modified with "_Results.xlsx" and "_Hits.xlsx"
    respectively, in the same location as the initial file input.
    
Usage:

```{r eval=FALSE}
# Example pipeline call
apply_TPP_pipeline(
  datafile = "path_to_data_input.csv",
  config = "path_to_config_file.csv",
  path = "[optional]_path_to_shared_dir",
  import_format = "format_name",
  to_plot = FALSE,
  max_cores = 4,
  silent = FALSE)
```
The character argument *import_format* defines which of the inbuilt import 
functions to use to read in data files. Currently:

* "Spectronaut", "SN" - imports from peptide tables exported from *Spectronaut* 
  DIA quantification reports.
  
* "ProteomeDiscoverer", "PD" - imports from protein tables exported from 
  *Thermo Proteome Discoverer* DDA quantification results.
  
* Default "Spectronaut".

The (boolean) argument *to_plot* defines whether to show automated plots across 
all methods; if *TRUE*, normalisation, NPARC score distribution, and hit 
melting-point curves will all be plotted. 

* Default *FALSE*.

The (integer) argument *max_cores* is passed to curve-fitting methods and 
defines maximum parallel cores to use for these operations. 

* Default *4*.

```{r apply_pipeline, results='hide', fig.show='hide', fig.dim=c(8,5)}
# Pipeline example: 4-protein test data
library(tidyTPP)

four_prot_report <-
    system.file("extdata", "4_protein_peptide_report.csv", package = "tidyTPP")
experiment_config <-
    system.file("extdata", "4_protein_config.csv", package = "tidyTPP")

# Apply pipeline
TPP_hits <- 
  apply_TPP_pipeline(datafile = four_prot_report,
                    config = experiment_config,
                    import_format = "spectronaut",
                    to_plot = TRUE,
                    max_cores = 4)


```

Result:

```{r pipeline_hits}
TPP_hits
```

![](`r knitr::fig_chunk('apply_pipeline', 'png', 4)`){width=75%}

## Example: Function detail

This example will walk through the main functions using 2-protein example data

### Import

*import_* functions read two files - quantification results output in a 
program-specific format, and a configuration file, defining conditions, 
replicates and temperatures, in the format shown.

```{r example_import}
# 4-protein example data
four_prot_report <-
    system.file("extdata", "4_protein_peptide_report.csv", package = "tidyTPP")
experiment_config <-
    system.file("extdata", "4_protein_config.csv", package = "tidyTPP")
experiment_dir <- system.file("extdata", package = "tidyTPP")
  
# Config file contents
read.csv(experiment_config)[1:10,]

# Import using spectronaut import format
four_prot_quan_data <- 
  import_spectronaut(datafile = "4_protein_peptide_report.csv",
                     config = "4_protein_config.csv",
                     path = experiment_dir)

# Resulting tibble
four_prot_quan_data

```

Data at this stage can be plotted to directly observe relative but *not yet 
normalised* protein curves.

``` {r example_import_plot, results='hide', fig.dim=c(8,7)}
plot_melt(four_prot_quan_data)

```

### Normalisation
*normalise_TPP* transforms relative TPP-TR relative intensity data, normalising 
against fitted median melting curves, as described by Savitsky *et al.* 2014.
`r citep("10.1126/science.1255784")`

``` {r example_normalisation, fig.dim=c(8,7), fig.show='hide'}
# Normalise four-protein data, with visualisation
four_prot_normalised <- 
  normalise_TPP(TPP_tbl = four_prot_quan_data,
                to_plot = TRUE)
```
![](`r knitr::fig_chunk('example_normalisation', 'png')`){width=75%}

Resulting in the normalised data:

```{r example_normalisation_plot, fig.show='hide', fig.dim=c(8,7)}
# Plotted melting data points
plot_melt(four_prot_normalised)
```
![](`r knitr::fig_chunk('example_normalisation_plot', 'png')`){width=75%}

### Analysis
*analyse_TPP* fits sigmoidal melting curves are fitted to each unique 
combination of protein, condition and replicate, and features of the curve 
(including $T_m$) calculated. Significance statistics are optionally calculated 
from the data:

* FDR-adjusted p-values are calculated for melting point differences from 
  control conditions ($\Delta T_m$) for each replicate
  `r citep("10.1126/science.1255784")`
  
* Scaled F-scores and FDR-adjusted p-values are calculated from *NPARC* analysis
  for each protein`r citep("10.1074/mcp.TIR119.001481")`
  
Default behaviour is to apply both analyses:

```{r example_analysis, results='hide', fig.dim=c(8,7)}
# Analyse four-protein data
four_prot_analysed <- 
  analyse_TPP(TPP_tbl = four_prot_normalised,
              control_name = "Control",
              p_value_methods = c("melting_point", "NPARC"))

# Analysed data and fitted curves
plot_melt(four_prot_analysed)
```

All statistics are appended as new measurements to the *tibble*:

```{r example_analysis_table}
# Full table
four_prot_analysed

# Statistics only
one_prot_stats <- 
  four_prot_analysed |>
  dplyr::filter(Protein_ID == "Protein_A", Condition != "Control") |>
  dplyr::select(Protein_ID, 
                Condition, 
                Replicate, 
                F_scaled, 
                p_adj_NPARC,
                melt_point,
                diff_melt_point,
                adj_pvalue
                ) |>
  dplyr::distinct()

# 1. Melting point
one_prot_stats |>
  dplyr::select(Protein_ID, 
                Condition, 
                Replicate,
                melt_point,
                diff_melt_point,
                adj_pvalue
                )

# 2. NPARC
one_prot_stats |>
  dplyr::select(Protein_ID, 
                Condition,
                F_scaled, 
                p_adj_NPARC,
                ) |>
  dplyr::distinct()
```

### Hit Identification

*get_TPP_hits* filters and summarises analysed data. Hits, by default, have an 
NPARC-derived, FDR-adjusted p-value below 0.05,
`r citep("10.1074/mcp.TIR119.001481")` $\Delta T_m$ in the same direction across 
replicates, and $\Delta T_m$ for comparisons against controls greater than 
between controls.`r citep("10.1126/science.1255784")`

```{r example_hits, fig.show='hide', fig.dim=c(8,5)}
# Get hits from analysed four-protein data
four_prot_hits <- 
  get_TPP_hits(TPP_data = four_prot_analysed,
               hit_criteria = "default_hit_criteria",
               to_plot = TRUE,
               annotate = "melt_point")

four_prot_hits
```
![](`r knitr::fig_chunk('example_hits', 'png')`){width=75%}

### Export

*get_TPP_hits* exported hit data by default, and full data can also be exported 
as an excel .xlsx spreadsheet with *export_TPP*. Alternatives are delimited text
files (.csv, .tsv) or R data.

```{r example_export, eval=FALSE}
# Export as .xlsx
export_TPP(TPP_data = four_prot_analysed,
           file_name = "TPP_results.xlsx",
           format = "xlsx")

```
## References
<!-- ### Bibliography -->
```{r bib, include=FALSE}
write.bibtex(file="man/bibliography/references.bib")
```
